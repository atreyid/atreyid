{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b04734",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-22T04:06:48.149394Z",
     "iopub.status.busy": "2022-03-22T04:06:48.148759Z",
     "iopub.status.idle": "2022-03-22T04:06:48.158392Z",
     "shell.execute_reply": "2022-03-22T04:06:48.159166Z",
     "shell.execute_reply.started": "2022-03-22T03:43:52.214640Z"
    },
    "papermill": {
     "duration": 0.053196,
     "end_time": "2022-03-22T04:06:48.159546",
     "exception": false,
     "start_time": "2022-03-22T04:06:48.106350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/test-data/testDatafinal.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238cfa5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:06:48.216792Z",
     "iopub.status.busy": "2022-03-22T04:06:48.216074Z",
     "iopub.status.idle": "2022-03-22T04:10:24.828633Z",
     "shell.execute_reply": "2022-03-22T04:10:24.829143Z",
     "shell.execute_reply.started": "2022-03-22T03:44:08.432368Z"
    },
    "papermill": {
     "duration": 216.637501,
     "end_time": "2022-03-22T04:10:24.829335",
     "exception": false,
     "start_time": "2022-03-22T04:06:48.191834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sparkmagic\r\n",
      "  Downloading sparkmagic-0.19.1.tar.gz (43 kB)\r\n",
      "     |████████████████████████████████| 43 kB 227 kB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting hdijupyterutils>=0.6\r\n",
      "  Downloading hdijupyterutils-0.19.1.tar.gz (5.0 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting autovizwidget>=0.6\r\n",
      "  Downloading autovizwidget-0.19.1.tar.gz (8.7 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: ipython>=4.0.2 in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (7.30.1)\r\n",
      "Requirement already satisfied: nose in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (1.3.7)\r\n",
      "Requirement already satisfied: mock in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (4.0.3)\r\n",
      "Requirement already satisfied: pandas>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (1.3.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (1.20.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (2.26.0)\r\n",
      "Collecting ipykernel<6.0.0\r\n",
      "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\r\n",
      "     |████████████████████████████████| 121 kB 1.6 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: ipywidgets>5.0.0 in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (7.6.5)\r\n",
      "Requirement already satisfied: notebook>=4.2 in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (6.4.6)\r\n",
      "Requirement already satisfied: tornado>=4 in /opt/conda/lib/python3.7/site-packages (from sparkmagic) (6.1)\r\n",
      "Collecting requests_kerberos>=0.8.0\r\n",
      "  Downloading requests_kerberos-0.14.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Requirement already satisfied: plotly>=3 in /opt/conda/lib/python3.7/site-packages (from autovizwidget>=0.6->sparkmagic) (5.6.0)\r\n",
      "Requirement already satisfied: jupyter>=1 in /opt/conda/lib/python3.7/site-packages (from hdijupyterutils>=0.6->sparkmagic) (1.0.0)\r\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel<6.0.0->sparkmagic) (5.1.1)\r\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel<6.0.0->sparkmagic) (7.1.0)\r\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from ipykernel<6.0.0->sparkmagic) (0.2.0)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (59.5.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (0.18.1)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (0.1.3)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (4.8.0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (5.1.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (3.0.24)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (0.2.0)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (0.7.5)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (2.10.0)\r\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>5.0.0->sparkmagic) (1.0.2)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>5.0.0->sparkmagic) (5.1.3)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>5.0.0->sparkmagic) (3.5.2)\r\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (0.12.0)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (1.5.4)\r\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (4.9.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (3.0.3)\r\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (21.1.0)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (0.12.1)\r\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (1.8.0)\r\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (6.3.0)\r\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (22.3.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.17.1->sparkmagic) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.17.1->sparkmagic) (2021.3)\r\n",
      "Collecting pyspnego[kerberos]\r\n",
      "  Downloading pyspnego-0.5.1-py2.py3-none-any.whl (122 kB)\r\n",
      "     |████████████████████████████████| 122 kB 7.0 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=1.3 in /opt/conda/lib/python3.7/site-packages (from requests_kerberos>=0.8.0->sparkmagic) (36.0.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->sparkmagic) (3.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->sparkmagic) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->sparkmagic) (1.26.7)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->sparkmagic) (2.0.9)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.7/site-packages (from cryptography>=1.3->requests_kerberos>=0.8.0->sparkmagic) (1.15.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.2->sparkmagic) (0.8.3)\r\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.7/site-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (6.4.0)\r\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.7/site-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (5.2.2)\r\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel<6.0.0->sparkmagic) (0.3)\r\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (4.3.1)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.2->sparkmagic) (0.7.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (1.16.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (8.0.1)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.2->sparkmagic) (0.2.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.2->sparkmagic) (2.1.1)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (4.1.0)\r\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.5.9)\r\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.7.1)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (1.5.0)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.1.2)\r\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.5.0)\r\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.8.4)\r\n",
      "Collecting gssapi>=1.5.0\r\n",
      "  Downloading gssapi-1.7.3.tar.gz (1.3 MB)\r\n",
      "     |████████████████████████████████| 1.3 MB 10.1 MB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting krb5>=0.3.0\r\n",
      "  Downloading krb5-0.3.0.tar.gz (1.7 MB)\r\n",
      "     |████████████████████████████████| 1.7 MB 67.2 MB/s            \r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=1.3->requests_kerberos>=0.8.0->sparkmagic) (2.21)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (4.11.3)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (21.2.0)\r\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (5.4.0)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (0.18.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (4.1.1)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.2->sparkmagic) (0.5.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.2->sparkmagic) (21.3)\r\n",
      "Requirement already satisfied: qtpy in /opt/conda/lib/python3.7/site-packages (from qtconsole->jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (1.11.3)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (3.6.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->bleach->nbconvert->notebook>=4.2->sparkmagic) (3.0.6)\r\n",
      "Building wheels for collected packages: sparkmagic, autovizwidget, hdijupyterutils, gssapi, krb5\r\n",
      "  Building wheel for sparkmagic (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sparkmagic: filename=sparkmagic-0.19.1-py3-none-any.whl size=64701 sha256=5ba3c6916559c83111ac5ec19c1432eeca09254511d01ed6ab72d86a535a0bcb\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/00/d5/153197547803fa423ee3d0a7a1ff19f138cbcc385a5d11e0dd\r\n",
      "  Building wheel for autovizwidget (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for autovizwidget: filename=autovizwidget-0.19.1-py3-none-any.whl size=14544 sha256=ea473f3eb969957284ab8f1b0cd5946ce051b4ae23a97a0f1ac0c399cba4061e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/76/d9/ff313b7bd4ff55b1ff8c299f31889f525dc5129556853e1330\r\n",
      "  Building wheel for hdijupyterutils (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for hdijupyterutils: filename=hdijupyterutils-0.19.1-py3-none-any.whl size=7675 sha256=b47807205f80eb5f28b4866b78b5a2fd923fd84e9805d0326a134d0c8eebd5c3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/64/eb/292698b4780fb4eed0d7521f8e8acac011eda244f368b88aa0\r\n",
      "  Building wheel for gssapi (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for gssapi: filename=gssapi-1.7.3-cp37-cp37m-linux_x86_64.whl size=3447409 sha256=454218e90505f8b62940093f599f2ce3211b54ae5990317bf49236911e038db9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/98/00/50c2dc63e573ee6526a8a64017272d5ecaddcd66034430b88b\r\n",
      "  Building wheel for krb5 (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for krb5: filename=krb5-0.3.0-cp37-cp37m-linux_x86_64.whl size=4294655 sha256=ea4a477756f3af0a2be953613fc63079babd3718a7880b8a06ea5eed57cf223f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/9c/5b/c797df276a5e2d9fd6ffd544aade607a6edae4428c0b511093\r\n",
      "Successfully built sparkmagic autovizwidget hdijupyterutils gssapi krb5\r\n",
      "Installing collected packages: ipykernel, pyspnego, krb5, gssapi, hdijupyterutils, requests-kerberos, autovizwidget, sparkmagic\r\n",
      "  Attempting uninstall: ipykernel\r\n",
      "    Found existing installation: ipykernel 6.6.0\r\n",
      "    Uninstalling ipykernel-6.6.0:\r\n",
      "      Successfully uninstalled ipykernel-6.6.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 3.1.6 requires google-cloud-bigquery-storage, which is not installed.\u001b[0m\r\n",
      "Successfully installed autovizwidget-0.19.1 gssapi-1.7.3 hdijupyterutils-0.19.1 ipykernel-5.5.6 krb5-0.3.0 pyspnego-0.5.1 requests-kerberos-0.14.0 sparkmagic-0.19.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\r\n",
      "     |████████████████████████████████| 281.4 MB 34 kB/s              \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting py4j==0.10.9.3\r\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\r\n",
      "     |████████████████████████████████| 198 kB 35.3 MB/s            \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=7a18b759f8ba52ff9716669151e08715e9ec3bf56ae9d25ea4d0f5baff962a95\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "  Attempting uninstall: py4j\r\n",
      "    Found existing installation: py4j 0.10.9.4\r\n",
      "    Uninstalling py4j-0.10.9.4:\r\n",
      "      Successfully uninstalled py4j-0.10.9.4\r\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sparkmagic\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae62419c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:25.266678Z",
     "iopub.status.busy": "2022-03-22T04:10:25.266026Z",
     "iopub.status.idle": "2022-03-22T04:10:31.420966Z",
     "shell.execute_reply": "2022-03-22T04:10:31.419491Z",
     "shell.execute_reply.started": "2022-03-22T03:48:21.862017Z"
    },
    "papermill": {
     "duration": 6.37336,
     "end_time": "2022-03-22T04:10:31.421180",
     "exception": false,
     "start_time": "2022-03-22T04:10:25.047820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/22 04:10:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from pyspark.sql import Row, Column\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.feature import StandardScaler, Imputer\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create PySpark SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4a56b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:31.921640Z",
     "iopub.status.busy": "2022-03-22T04:10:31.920933Z",
     "iopub.status.idle": "2022-03-22T04:10:31.935443Z",
     "shell.execute_reply": "2022-03-22T04:10:31.936023Z",
     "shell.execute_reply.started": "2022-03-22T03:58:01.406642Z"
    },
    "papermill": {
     "duration": 0.256678,
     "end_time": "2022-03-22T04:10:31.936200",
     "exception": false,
     "start_time": "2022-03-22T04:10:31.679522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_flights_weather_sm = pd.read_csv('/kaggle/input/test-data/testDatafinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9c3913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:32.374333Z",
     "iopub.status.busy": "2022-03-22T04:10:32.373650Z",
     "iopub.status.idle": "2022-03-22T04:10:32.389813Z",
     "shell.execute_reply": "2022-03-22T04:10:32.390278Z",
     "shell.execute_reply.started": "2022-03-22T03:58:03.076004Z"
    },
    "papermill": {
     "duration": 0.240032,
     "end_time": "2022-03-22T04:10:32.390441",
     "exception": false,
     "start_time": "2022-03-22T04:10:32.150409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_flights_weather_sm['YEAR_OBS']= pd.to_datetime(df_flights_weather_sm['YEAR_OBS'])\n",
    "df_flights_weather_sm['YEAR_OBS'] = pd.DatetimeIndex(df_flights_weather_sm['YEAR_OBS']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8f3408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:32.818624Z",
     "iopub.status.busy": "2022-03-22T04:10:32.817944Z",
     "iopub.status.idle": "2022-03-22T04:10:35.372075Z",
     "shell.execute_reply": "2022-03-22T04:10:35.371396Z",
     "shell.execute_reply.started": "2022-03-22T03:58:19.433647Z"
    },
    "papermill": {
     "duration": 2.769099,
     "end_time": "2022-03-22T04:10:35.372214",
     "exception": false,
     "start_time": "2022-03-22T04:10:32.603115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NEIGHBOR_ID: long (nullable = true)\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- DEP_HOUR_OF: long (nullable = true)\n",
      " |-- MONTH: long (nullable = true)\n",
      " |-- YEAR: long (nullable = true)\n",
      " |-- STATION: long (nullable = true)\n",
      " |-- DATE_OBS: string (nullable = true)\n",
      " |-- FLIGHT_HOUR_OBS: long (nullable = true)\n",
      " |-- MONTH_OBS: long (nullable = true)\n",
      " |-- YEAR_OBS: long (nullable = true)\n",
      " |-- DEP_DEL15: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF=spark.createDataFrame(df_flights_weather_sm) \n",
    "sparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e2aeb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:35.801679Z",
     "iopub.status.busy": "2022-03-22T04:10:35.801007Z",
     "iopub.status.idle": "2022-03-22T04:10:35.803424Z",
     "shell.execute_reply": "2022-03-22T04:10:35.802867Z",
     "shell.execute_reply.started": "2022-03-22T03:58:33.145885Z"
    },
    "papermill": {
     "duration": 0.218937,
     "end_time": "2022-03-22T04:10:35.803553",
     "exception": false,
     "start_time": "2022-03-22T04:10:35.584616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hold_out_variable = 'YEAR_OBS'\n",
    "hold_out_threshold = '2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad946689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:36.246229Z",
     "iopub.status.busy": "2022-03-22T04:10:36.245517Z",
     "iopub.status.idle": "2022-03-22T04:10:36.971761Z",
     "shell.execute_reply": "2022-03-22T04:10:36.971118Z",
     "shell.execute_reply.started": "2022-03-22T03:58:42.659572Z"
    },
    "papermill": {
     "duration": 0.955534,
     "end_time": "2022-03-22T04:10:36.971920",
     "exception": false,
     "start_time": "2022-03-22T04:10:36.016386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainDF = sparkDF.filter(sparkDF[hold_out_variable]!=hold_out_threshold).cache()\n",
    "testDF = sparkDF.filter(sparkDF[hold_out_variable]==hold_out_threshold).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88915e22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:37.421851Z",
     "iopub.status.busy": "2022-03-22T04:10:37.421009Z",
     "iopub.status.idle": "2022-03-22T04:10:37.620637Z",
     "shell.execute_reply": "2022-03-22T04:10:37.621166Z"
    },
    "papermill": {
     "duration": 0.435918,
     "end_time": "2022-03-22T04:10:37.621339",
     "exception": false,
     "start_time": "2022-03-22T04:10:37.185421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NEIGHBOR_ID: long (nullable = true)\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- DEP_HOUR_OF: long (nullable = true)\n",
      " |-- MONTH: long (nullable = true)\n",
      " |-- YEAR: long (nullable = true)\n",
      " |-- STATION: long (nullable = true)\n",
      " |-- DATE_OBS: string (nullable = true)\n",
      " |-- FLIGHT_HOUR_OBS: long (nullable = true)\n",
      " |-- MONTH_OBS: long (nullable = true)\n",
      " |-- YEAR_OBS: long (nullable = true)\n",
      " |-- DEP_DEL15: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF=spark.createDataFrame(df_flights_weather_sm) \n",
    "sparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a4aab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:38.055458Z",
     "iopub.status.busy": "2022-03-22T04:10:38.054818Z",
     "iopub.status.idle": "2022-03-22T04:10:41.891289Z",
     "shell.execute_reply": "2022-03-22T04:10:41.890206Z",
     "shell.execute_reply.started": "2022-03-22T03:58:52.759324Z"
    },
    "papermill": {
     "duration": 4.05522,
     "end_time": "2022-03-22T04:10:41.891509",
     "exception": false,
     "start_time": "2022-03-22T04:10:37.836289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|YEAR_OBS|count|\n",
      "+--------+-----+\n",
      "|    2016|  199|\n",
      "|    2015|  200|\n",
      "|    2017|  201|\n",
      "|    2018|  200|\n",
      "+--------+-----+\n",
      "\n",
      "+--------+-----+\n",
      "|YEAR_OBS|count|\n",
      "+--------+-----+\n",
      "|    2019|  200|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy('YEAR_OBS').count().show()\n",
    "testDF.groupBy('YEAR_OBS').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d83f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:42.544526Z",
     "iopub.status.busy": "2022-03-22T04:10:42.543646Z",
     "iopub.status.idle": "2022-03-22T04:10:42.688193Z",
     "shell.execute_reply": "2022-03-22T04:10:42.687448Z",
     "shell.execute_reply.started": "2022-03-22T03:59:10.583255Z"
    },
    "papermill": {
     "duration": 0.444413,
     "end_time": "2022-03-22T04:10:42.688343",
     "exception": false,
     "start_time": "2022-03-22T04:10:42.243930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "minor_df = trainDF.filter(col('DEP_DEL15')==1).cache()\n",
    "major_df = trainDF.filter(col('DEP_DEL15')==0).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7a3d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:43.125574Z",
     "iopub.status.busy": "2022-03-22T04:10:43.124894Z",
     "iopub.status.idle": "2022-03-22T04:10:43.857967Z",
     "shell.execute_reply": "2022-03-22T04:10:43.857146Z",
     "shell.execute_reply.started": "2022-03-22T03:59:17.731057Z"
    },
    "papermill": {
     "duration": 0.954711,
     "end_time": "2022-03-22T04:10:43.858179",
     "exception": false,
     "start_time": "2022-03-22T04:10:42.903468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_ontime = major_df.count()\n",
    "n_delays = minor_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad64ebe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:44.385818Z",
     "iopub.status.busy": "2022-03-22T04:10:44.385156Z",
     "iopub.status.idle": "2022-03-22T04:10:44.388194Z",
     "shell.execute_reply": "2022-03-22T04:10:44.387676Z",
     "shell.execute_reply.started": "2022-03-22T03:59:30.469564Z"
    },
    "papermill": {
     "duration": 0.228271,
     "end_time": "2022-03-22T04:10:44.388327",
     "exception": false,
     "start_time": "2022-03-22T04:10:44.160056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of on-time to delayed flights is of 10.3:1\n"
     ]
    }
   ],
   "source": [
    "ratio = n_ontime/n_delays\n",
    "print('The ratio of on-time to delayed flights is of {:0.1f}:1'.format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "753e411f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:44.821977Z",
     "iopub.status.busy": "2022-03-22T04:10:44.821353Z",
     "iopub.status.idle": "2022-03-22T04:10:45.544440Z",
     "shell.execute_reply": "2022-03-22T04:10:45.545248Z",
     "shell.execute_reply.started": "2022-03-22T03:59:44.238243Z"
    },
    "papermill": {
     "duration": 0.94217,
     "end_time": "2022-03-22T04:10:45.545506",
     "exception": false,
     "start_time": "2022-03-22T04:10:44.603336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|DEP_DEL15|count|\n",
      "+---------+-----+\n",
      "|        0|  729|\n",
      "|        1|  721|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample_df = minor_df.sample(withReplacement=True, fraction=ratio, seed=321)\n",
    "augmentedTrainDF = major_df.unionAll(oversample_df).cache()\n",
    "augmentedTrainDF.groupBy('DEP_DEL15').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2d1afc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:46.117082Z",
     "iopub.status.busy": "2022-03-22T04:10:46.115970Z",
     "iopub.status.idle": "2022-03-22T04:10:46.596961Z",
     "shell.execute_reply": "2022-03-22T04:10:46.597925Z",
     "shell.execute_reply.started": "2022-03-22T04:00:07.869558Z"
    },
    "papermill": {
     "duration": 0.709945,
     "end_time": "2022-03-22T04:10:46.598201",
     "exception": false,
     "start_time": "2022-03-22T04:10:45.888256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_obs, fold_number mapping: {2016: 1, 2015: 0, 2017: 2, 2018: 3}\n"
     ]
    }
   ],
   "source": [
    "fold_variable = 'YEAR_OBS'\n",
    "fold_list = augmentedTrainDF.select(fold_variable).distinct().toPandas()[fold_variable]\n",
    "mapping = {x: x - fold_list.min() for x in fold_list}\n",
    "print(f'{fold_variable.capitalize()}, fold_number mapping: {mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e671229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:47.271283Z",
     "iopub.status.busy": "2022-03-22T04:10:47.270348Z",
     "iopub.status.idle": "2022-03-22T04:10:47.273705Z",
     "shell.execute_reply": "2022-03-22T04:10:47.274230Z",
     "shell.execute_reply.started": "2022-03-22T04:00:19.348545Z"
    },
    "papermill": {
     "duration": 0.31216,
     "end_time": "2022-03-22T04:10:47.274402",
     "exception": false,
     "start_time": "2022-03-22T04:10:46.962242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of folds: 3\n"
     ]
    }
   ],
   "source": [
    "nFolds = len(fold_list) - 1\n",
    "print(f'Total number of folds: {nFolds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48dc327d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:47.725907Z",
     "iopub.status.busy": "2022-03-22T04:10:47.725230Z",
     "iopub.status.idle": "2022-03-22T04:10:47.728317Z",
     "shell.execute_reply": "2022-03-22T04:10:47.728918Z",
     "shell.execute_reply.started": "2022-03-22T04:01:12.803440Z"
    },
    "papermill": {
     "duration": 0.226172,
     "end_time": "2022-03-22T04:10:47.729089",
     "exception": false,
     "start_time": "2022-03-22T04:10:47.502917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2016: 1, 2015: 0, 2017: 2, 2018: 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "949d6f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:48.172604Z",
     "iopub.status.busy": "2022-03-22T04:10:48.171542Z",
     "iopub.status.idle": "2022-03-22T04:10:48.332750Z",
     "shell.execute_reply": "2022-03-22T04:10:48.331198Z",
     "shell.execute_reply.started": "2022-03-22T04:01:15.403375Z"
    },
    "papermill": {
     "duration": 0.383557,
     "end_time": "2022-03-22T04:10:48.332983",
     "exception": false,
     "start_time": "2022-03-22T04:10:47.949426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add 'foldCol' to TrainDF\n",
    "# mapping_expr = create_map([lit(x) for x in chain(*mapping.items())]\n",
    "mapping_expr = create_map([lit(x) for x in chain(*mapping.items())])\n",
    "foldedTrainDF = augmentedTrainDF.withColumn('foldCol', mapping_expr[col(fold_variable)]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81006970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T04:10:48.791177Z",
     "iopub.status.busy": "2022-03-22T04:10:48.790468Z",
     "iopub.status.idle": "2022-03-22T04:10:48.794259Z",
     "shell.execute_reply": "2022-03-22T04:10:48.793749Z",
     "shell.execute_reply.started": "2022-03-22T04:01:34.749045Z"
    },
    "papermill": {
     "duration": 0.23374,
     "end_time": "2022-03-22T04:10:48.794390",
     "exception": false,
     "start_time": "2022-03-22T04:10:48.560650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesCrossValidator(CrossValidator):\n",
    "    '''\n",
    "    Customizes CrossValidator to perform time series cross validation on a rolling basis.\n",
    "    User needs to provide `foldCol` with the fold numbers defined in a time ascending order\n",
    "    (e.g. 2015 is assigned as fold 0, 2016 as fold 1, and so on).\n",
    "    '''\n",
    "    def _kFold(self, dataset):\n",
    "        nFolds = self.getOrDefault(self.numFolds)\n",
    "        foldCol = self.getOrDefault(self.foldCol)\n",
    "\n",
    "        datasets = []\n",
    "        if not foldCol:\n",
    "            # Do random k-fold split.\n",
    "            seed = self.getOrDefault(self.seed)\n",
    "            h = 1.0 / nFolds\n",
    "            randCol = self.uid + \"_rand\"\n",
    "            df = dataset.select(\"*\", rand(seed).alias(randCol))\n",
    "            for i in range(nFolds):\n",
    "                validateLB = i * h\n",
    "                validateUB = (i + 1) * h\n",
    "                condition = (df[randCol] >= validateLB) & (df[randCol] < validateUB)\n",
    "                validation = df.filter(condition)\n",
    "                train = df.filter(~condition)\n",
    "                datasets.append((train, validation))\n",
    "        else:\n",
    "            # Use user-specified fold numbers.\n",
    "            def checker(foldNum):\n",
    "                if foldNum < 0 or foldNum > nFolds:\n",
    "                    raise ValueError(\n",
    "                        \"Fold number must be in range [0, %s], but got %s.\" % (nFolds, foldNum)\n",
    "                    )\n",
    "                return True\n",
    "\n",
    "            checker_udf = UserDefinedFunction(checker, BooleanType())\n",
    "            for i in range(nFolds):\n",
    "                training = dataset.filter(checker_udf(dataset[foldCol]) & (col(foldCol) <= lit(i))) # Training set always in the past\n",
    "                validation = dataset.filter(\n",
    "                    checker_udf(dataset[foldCol]) & (col(foldCol) == lit(i+1)) # Validation set always in the future\n",
    "                )\n",
    "                if training.rdd.getNumPartitions() == 0 or len(training.take(1)) == 0:\n",
    "                    raise ValueError(\"The training data at fold %s is empty.\" % i)\n",
    "                if validation.rdd.getNumPartitions() == 0 or len(validation.take(1)) == 0:\n",
    "                    raise ValueError(\"The validation data at fold %s is empty.\" % i)\n",
    "                datasets.append((training, validation))\n",
    "\n",
    "        return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e8404",
   "metadata": {
    "papermill": {
     "duration": 0.217156,
     "end_time": "2022-03-22T04:10:49.230060",
     "exception": false,
     "start_time": "2022-03-22T04:10:49.012904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23df05",
   "metadata": {
    "papermill": {
     "duration": 0.214517,
     "end_time": "2022-03-22T04:10:49.665247",
     "exception": false,
     "start_time": "2022-03-22T04:10:49.450730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 251.922248,
   "end_time": "2022-03-22T04:10:50.598470",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-22T04:06:38.676222",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
